{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNHRJuB8C0xMc+cYp29vfJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanesq/2-Months-Project-LLM/blob/main/LlamaIndex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0ZxuBFml2bNQ"
      },
      "outputs": [],
      "source": [
        "pip install llama-index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **python-docx2txt**\n",
        "A pure python-based utility to extract text from docx files.\n",
        "\n",
        "The code is taken and adapted from python-docx. It can however also extract text from header, footer and hyperlinks. It can now also extract images."
      ],
      "metadata": {
        "id": "xTwNTb774SM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx2txt"
      ],
      "metadata": {
        "id": "3a_t3Uqn30gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.readers.file.docs import DocxReader\n",
        "docx_reader = DocxReader()\n",
        "document_1 = docx_reader.load_data('/content/trial.docx')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "78aCX84f3bo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chunking Randomly\n",
        "[Documentation to TokenTextSplitter](https://docs.llamaindex.ai/en/v0.10.17/api/llama_index.core.node_parser.TokenTextSplitter.html#tokentextsplitter)"
      ],
      "metadata": {
        "id": "fMKb0x7X8N0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "splitter = TokenTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=100,\n",
        "    separator=\" \",\n",
        ")"
      ],
      "metadata": {
        "id": "PliwvuN98A7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_nodes = splitter.get_nodes_from_documents(\n",
        "    document_1, show_progress=True\n",
        ")"
      ],
      "metadata": {
        "id": "IVCTuBZx8UN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V9LNsMxL3mLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM SETUP\n",
        "*   [HuggingFaceLLM](https://docs.llamaindex.ai/en/v0.9.48/api_reference/llms/huggingface.html#huggingfacellm)\n",
        "*   [Llama 3.2 3B\n",
        "](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)\n",
        "\n"
      ],
      "metadata": {
        "id": "OjBW1EYf3789"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install llama-index-llms-huggingface"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PGKPWDaO57iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.huggingface import HuggingFaceLLM"
      ],
      "metadata": {
        "id": "OSdcXwZ45Gjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a Q&A assistant. Your goal is to answer questions as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "YuJd7eEpfVa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "    model_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "    device_map=\"auto\",\n",
        "    # loading model in 8bit for reducing memory\n",
        "    #model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Xv8YZWA-37bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Embedding & Vectorization**\n"
      ],
      "metadata": {
        "id": "IGD2jFHA9X0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Imports"
      ],
      "metadata": {
        "id": "UgLe4LSw9kOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "#NOT REQUIRED SimpleDirectoryReader, ServiceContext  #Vector store index is for indexing the vector\n"
      ],
      "metadata": {
        "id": "IDkCyu-59grv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding Imports\n",
        "* [HuggingFaceEmbeddings](https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface/)  \n",
        "*   [LAngchain HF Embedding](https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html#huggingfaceembeddings)\n",
        "*   [SBERT](https://www.sbert.net/)\n",
        "*   [Llamindex embedding](https://docs.llamaindex.ai/en/stable/api_reference/embeddings/huggingface/)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Os8pUhAx9qu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hl8zcJMXZF8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# Set up the HuggingFaceEmbedding class with the required model to use with llamaindex core.\n",
        "embed_model  = HuggingFaceEmbedding(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CPyBaBFJNC3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rMioPck2a_aR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Service Context/Settings"
      ],
      "metadata": {
        "id": "zNpgXCrIEVeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from llama_index.core import ServiceContext this is obsolote\n",
        "from llama_index.core import Settings"
      ],
      "metadata": {
        "id": "eESFUNNLEYLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up\n",
        "Edit  : ServiceContext is deprecated.\n",
        "\n",
        "*   Use llama_index.settings.Settings instead\n",
        "*   [Migration to Settings Llama Index](https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/)\n"
      ],
      "metadata": {
        "id": "BWxiRi0oElh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.llm=llm\n",
        "Settings.embed_model=embed_model\n",
        "Settings.node_parser=splitter"
      ],
      "metadata": {
        "id": "5HixP8C-Fuqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing"
      ],
      "metadata": {
        "id": "g5zt31dSbK2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "index=VectorStoreIndex.from_documents(document_1)#no longer required to have servicecontext\n",
        "query_engine=index.as_query_engine()"
      ],
      "metadata": {
        "id": "S_YkUtdhEkN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Query"
      ],
      "metadata": {
        "id": "Qkcl7PgZaji5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   [Querying LlamaIndex](https://docs.llamaindex.ai/en/stable/module_guides/querying/)\n",
        "*   [Query Engine Module\n",
        "](https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/modules/)\n"
      ],
      "metadata": {
        "id": "S6XwQc_GcJBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Query engine **[not working]**"
      ],
      "metadata": {
        "id": "HiEkZZxwg7_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import llama_index\n",
        "from llama_index.retrievers import VectorIndexRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.indices.postprocessor import SimilarityPostprocessor\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i1mx_dDihg8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.retrievers import VectorIndexRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "retriever=VectorIndexRetriever(index=index,similarity_top_k=4)\n",
        "postprocessor=SimilarityPostprocessor(similarity_cutoff=0.80)\n",
        "\n",
        "query_engine=RetrieverQueryEngine(retriever=retriever,\n",
        "                                  node_postprocessors=[postprocessor])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XwMU6b8vgzJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vanilla Query Response**"
      ],
      "metadata": {
        "id": "crMMKDcqi1g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response=query_engine.query(\"what is this document?\")\n",
        "#response.source_nodes[0].node.get_text()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "peLUp6ydal1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "id": "MbgyPPg-fDAe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}