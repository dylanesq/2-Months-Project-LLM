{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dylanesq/2-Months-Project-LLM/blob/main/LlamaIndexV2_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0ZxuBFml2bNQ"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTwNTb774SM6"
      },
      "source": [
        "#Loading\n",
        "\n",
        " **python-docx2txt**\n",
        "A pure python-based utility to extract text from docx files.\n",
        "\n",
        "The code is taken and adapted from python-docx. It can however also extract text from header, footer and hyperlinks. It can now also extract images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a_t3Uqn30gC"
      },
      "outputs": [],
      "source": [
        "pip install docx2txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try using raw github dump for loading"
      ],
      "metadata": {
        "id": "0CKseJnGf20K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "78aCX84f3bo-"
      },
      "outputs": [],
      "source": [
        "#from llama_index.readers.file.docs import DocxReader\n",
        "from llama_index.core import SimpleDirectoryReader\n",
        "#docx_reader = DocxReader()\n",
        "#document_1 = docx_reader.load_data('/content/drive/MyDrive/002MONTHSPROJECT/')\n",
        "reader=SimpleDirectoryReader(input_dir=\"/content/drive/MyDrive/002MONTHSPROJECT/\", required_exts=[\".docx\"])\n",
        "document_1=reader.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMKb0x7X8N0Z"
      },
      "source": [
        "# Chunking Randomly\n",
        "[TokenTextSplitter](https://docs.llamaindex.ai/en/v0.10.17/api/llama_index.core.node_parser.TokenTextSplitter.html#tokentextsplitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PliwvuN98A7C"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import TokenTextSplitter\n",
        "splitter = TokenTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=100,\n",
        "    separator=\" \",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3rilenkQ393"
      },
      "source": [
        "*For Review Purpose*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVCTuBZx8UN1"
      },
      "outputs": [],
      "source": [
        "token_nodes = splitter.get_nodes_from_documents(\n",
        "    document_1, show_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjBW1EYf3789"
      },
      "source": [
        "# LLM Setup\n",
        "*   [HuggingFaceLLM](https://docs.llamaindex.ai/en/v0.9.48/api_reference/llms/huggingface.html#huggingfacellm)\n",
        "*   [Llama 3.2 3B\n",
        "](https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "update : logging without CLI *(contains exposed HF Token , how to fix)*"
      ],
      "metadata": {
        "id": "e5fXUBPhHX0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title LOGIN INFO [ HIDDEN]\n",
        "!huggingface-cli login --token HF_TOKEN --add-to-git-credential"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7AhBx3bdIZoy",
        "outputId": "2638cde6-1cd4-4cb1-92a0-2f60210b01de"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: fineGrained).\n",
            "The token `llama3forAnkan` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `llama3forAnkan`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli whoami\n",
        "#!huggingface-cli logout"
      ],
      "metadata": {
        "id": "4ooAIcnDJwY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLM Init."
      ],
      "metadata": {
        "id": "piw5VLQMhaPi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PGKPWDaO57iQ"
      },
      "outputs": [],
      "source": [
        "!pip install llama_index.llms.huggingface\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "system prompt"
      ],
      "metadata": {
        "id": "DKHYiiM_hkl-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuJd7eEpfVa6"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a Q&A assistant. Your goal is to answer questions as\n",
        "accurately as possible based on the instructions and context provided.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2Y6YXclbWql"
      },
      "source": [
        "Quantization [ 8 bit Working]\n",
        "\n",
        "[HF Bits&Bytesconfig](https://huggingface.co/docs/transformers/en/main_classes/quantization#transformers.BitsAndBytesConfig)\n",
        "[Bitnbytes docu](https://pypi.org/project/bitsandbytes/https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OhpRHzFcbxfY"
      },
      "outputs": [],
      "source": [
        "!pip install -U bitsandbytes\n",
        "!pip install accelerate\n",
        "#!pip install --upgrade transformers accelerate bitsandbytes\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "import torch\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DUM5MFtbWNv"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFaceLLM(\n",
        "        context_window=4096,\n",
        "        max_new_tokens=256,\n",
        "        generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "        system_prompt=system_prompt,\n",
        "        tokenizer_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "        model_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n",
        "        device_map=\"auto\", # Ensures the model is loaded on the GPU if available\n",
        "        # Pass the quantization_config object here\n",
        "        model_kwargs={\n",
        "            \"torch_dtype\": torch.float16, # Recommended for performance on GPU\n",
        "            \"quantization_config\": quantization_config # Pass the BitsAndBytesConfig object\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"After Quantisation :\"(llm.get_memory_footprint())/1e9) need to rework this"
      ],
      "metadata": {
        "id": "aKxfxuVX1ITl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGD2jFHA9X0f"
      },
      "source": [
        "# **Embedding & Vectorization**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgLe4LSw9kOJ"
      },
      "source": [
        "Vector Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDkCyu-59grv"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "#NOT REQUIRED SimpleDirectoryReader, ServiceContext  #Vector store index is for indexing the vector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os8pUhAx9qu3"
      },
      "source": [
        "Embedding Imports\n",
        "* [HuggingFaceEmbeddings](https://docs.llamaindex.ai/en/stable/examples/embeddings/huggingface/)  \n",
        "*   [LAngchain HF Embedding](https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html#huggingfaceembeddings)\n",
        "*   [SBERT](https://www.sbert.net/)\n",
        "*   [Llamindex embedding](https://docs.llamaindex.ai/en/stable/api_reference/embeddings/huggingface/)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hl8zcJMXZF8l"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-embeddings-huggingface\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# Set up the HuggingFaceEmbedding class with the required model to use with llamaindex core.\n",
        "embed_model  = HuggingFaceEmbedding(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNpgXCrIEVeB"
      },
      "source": [
        "# Service Context/Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWxiRi0oElh3"
      },
      "source": [
        "Set Up\n",
        "Edit  : ServiceContext is deprecated.\n",
        "\n",
        "*   Use llama_index.settings.Settings instead\n",
        "*   [Migration to Settings Llama Index](https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eESFUNNLEYLI"
      },
      "outputs": [],
      "source": [
        "# from llama_index.core import ServiceContext this is obsolote\n",
        "from llama_index.core import Settings\n",
        "Settings.llm=llm\n",
        "Settings.embed_model=embed_model\n",
        "Settings.node_parser=splitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5zt31dSbK2E"
      },
      "source": [
        "#Indexing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_YkUtdhEkN6"
      },
      "outputs": [],
      "source": [
        "\n",
        "index=VectorStoreIndex.from_documents(document_1)#no longer required to have servicecontext\n",
        "#query_engine=index.as_query_engine(topK=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkcl7PgZaji5"
      },
      "source": [
        "#Query Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6XwQc_GcJBU"
      },
      "source": [
        "\n",
        "\n",
        "*   [Querying LlamaIndex](https://docs.llamaindex.ai/en/stable/module_guides/querying/)\n",
        "*   [Query Engine Module\n",
        "](https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/modules/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiEkZZxwg7_G"
      },
      "source": [
        "Custom Query engine **[working]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "collapsed": true,
        "id": "XwMU6b8vgzJG"
      },
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "#from llama_index.core.indices.postprocessor import SimilarityPostprocessor\n",
        "\n",
        "retriever=VectorIndexRetriever(index=index,similarity_top_k=5)\n",
        "#postprocessor=SimilarityPostprocessor(similarity_cutoff=0.60)\n",
        "\n",
        "query_engine=RetrieverQueryEngine(retriever=retriever)\n",
        "#query_engine=RetrieverQueryEngine(retriever=retriever,node_postprocessors=[postprocessor])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crMMKDcqi1g9"
      },
      "source": [
        "**Vanilla Query Response**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"what is this document about?\""
      ],
      "metadata": {
        "id": "vERJ3Lq8-qHj"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Responses"
      ],
      "metadata": {
        "id": "3MzPfQ6c5EnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "norank_retrieved_nodes = retriever.retrieve(prompt)\n",
        "print(f\"Retrieved {len(norank_retrieved_nodes)} nodes:\")\n",
        "for i, node in enumerate(norank_retrieved_nodes):\n",
        "    print(f\"\\n--- Node {i + 1} ---\")\n",
        "    print(node.get_content())\n",
        "    print(f\"Score: {node.score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OA5V_0v3jawl",
        "outputId": "9d54ce83-4cac-4b6f-9b68-5da0c0489368"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved 2 nodes:\n",
            "\n",
            "--- Node 1 ---\n",
            "ante odio, ut interdum tellus imperdiet vitae. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse commodo, tellus ac varius egestas, magna nisi condimentum nunc, vitae tincidunt nisl lorem eget eros. Duis tristique ultrices magna, a varius ligula ornare pharetra. Fusce luctus nisl est, ac semper nunc dignissim tempor.\n",
            "\n",
            "Praesent sed lorem lorem. Donec egestas eros nec rhoncus efficitur. Duis nec mi arcu. Suspendisse in elit elit. Suspendisse potenti. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Quisque mattis metus eu nisi commodo, in semper orci malesuada. Nullam ullamcorper dapibus dolor in egestas.\n",
            "\n",
            "Aenean faucibus dui sit amet interdum laoreet. Sed ac pretium arcu, at dictum nisl. Donec ullamcorper ac diam et finibus. Suspendisse hendrerit lorem sem, ut mattis ipsum malesuada vel. Morbi ullamcorper elementum viverra. Fusce eget placerat urna, et ornare tortor. Suspendisse facilisis lorem at nunc semper rhoncus. Quisque volutpat non est vitae dapibus. Suspendisse imperdiet facilisis nibh nec sodales.\n",
            "\n",
            "Cras sagittis porttitor odio, in pretium mauris finibus ut. Aliquam venenatis magna massa, id accumsan mi blandit quis. In vehicula euismod mollis. Donec volutpat, tortor in auctor cursus, urna nibh scelerisque magna, nec consectetur odio magna nec nisi. Suspendisse commodo euismod diam eget rutrum. Suspendisse vel laoreet ex. In sed sodales nisl. Sed et hendrerit magna. Suspendisse pulvinar id elit sit amet scelerisque. Suspendisse dictum nisl in sapien iaculis ultrices in a risus. In tristique sapien est, vel mollis magna egestas at. Aenean ullamcorper nisl at metus feugiat, non egestas urna bibendum.\n",
            "\n",
            "Quisque pharetra ac nunc at tincidunt. Nulla vel ipsum nec elit blandit hendrerit. Quisque magna eros, imperdiet non elementum id, blandit nec eros. Etiam pharetra condimentum mi, sit amet dictum dolor vulputate ut. Nam pellentesque velit a ullamcorper condimentum. Integer orci dui, elementum non augue non, accumsan facilisis augue. Phasellus pharetra lorem et eros vehicula varius. Vestibulum elementum nunc eget sagittis laoreet. Suspendisse mauris massa, aliquet sed eros ac, tempus elementum nisl. Integer vel congue libero, at sagittis dui. Aliquam viverra nisl dolor, ac volutpat neque maximus vel. Etiam faucibus fermentum nulla malesuada rutrum. Pellentesque imperdiet tincidunt augue.\n",
            "\n",
            "Phasellus sagittis quis justo gravida placerat. Praesent congue mattis nulla, vitae vehicula tortor efficitur in. Maecenas cursus odio risus, dictum molestie enim pulvinar ut. Praesent nibh erat, accumsan a tellus vel, fringilla ultrices sem. Donec vel enim a orci mollis scelerisque. Mauris at imperdiet metus. Nulla commodo fermentum ex a varius. Morbi ac quam non nisl pellentesque feugiat. Praesent a aliquet elit, vitae imperdiet felis. Donec bibendum ipsum metus, quis rhoncus orci convallis at. Duis pharetra nisl id blandit malesuada. Donec sodales a eros fringilla congue.\n",
            "\n",
            "Etiam eleifend massa non sapien viverra fringilla. Vivamus tempor sodales ante eu finibus. Phasellus sit amet elementum diam. Phasellus eget diam diam. Nunc rutrum lacus ut elementum congue. Donec justo felis, tempus ac sodales vitae, faucibus sit amet nibh. Nam consequat sit amet nisi a hendrerit. Ut auctor non lectus eu semper. Curabitur sollicitudin libero vitae ante pulvinar, vel laoreet nunc finibus. Praesent vel convallis\n",
            "Score: 0.18062013069197172\n",
            "\n",
            "--- Node 2 ---\n",
            "consequat quis quam ut facilisis. Nam non magna cursus massa semper mattis. Vivamus rhoncus, augue vitae efficitur posuere, mauris justo laoreet neque, in iaculis tellus erat ut ipsum. Suspendisse odio augue, tincidunt id lectus sed, hendrerit efficitur sem. Duis vitae nibh pulvinar, tincidunt orci a, mollis ex. Integer condimentum justo enim, eget ultricies libero bibendum sed. Duis magna mi, mattis sit \n",
            "\n",
            "\n",
            "\n",
            "amet diam quis, efficitur vehicula est. Etiam tincidunt turpis urna, ut dignissim risus lacinia in. Suspendisse a mollis magna, eu feugiat massa. Ut vitae erat vel tellus condimentum placerat venenatis a erat.\n",
            "\n",
            "Suspendisse molestie nibh magna, eu maximus ante tincidunt tincidunt. Ut sit amet bibendum turpis, vitae iaculis nibh. Pellentesque consectetur facilisis sem, sed vehicula quam consectetur dapibus. Praesent eget urna aliquet, sollicitudin massa ut, tempor quam. In vehicula feugiat dui sed feugiat. Nulla laoreet placerat dui, congue placerat massa lobortis in. Curabitur eu pellentesque enim, vel congue dolor. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed placerat vulputate risus a convallis. Suspendisse laoreet volutpat libero id vulputate. Quisque sit amet scelerisque elit, vel ultrices felis. Vivamus tristique ex vitae maximus commodo.\n",
            "\n",
            "Donec vestibulum tellus nec pellentesque imperdiet. Praesent fringilla molestie felis ut porta. Cras ac finibus ante. In ultricies nec sapien ac cursus. Duis semper scelerisque mi, non posuere urna scelerisque non. Pellentesque orci dui, scelerisque nec bibendum at, pellentesque vel nulla. Curabitur nec tempus ante. Praesent tortor arcu, egestas eu tellus nec, aliquam porta velit. Nam et urna id sem aliquam gravida. Suspendisse lacus ligula, facilisis ut sapien non, eleifend sodales risus. In a lacus eu nisi accumsan vulputate sed fringilla quam. Vivamus eros erat, suscipit vel rhoncus eu, venenatis sed mauris. Ut mollis imperdiet elit, vel vulputate massa ultricies non. Duis fermentum lectus ac lorem venenatis tempor.\n",
            "\n",
            "Integer in vestibulum magna, a ornare dolor. Donec consectetur vestibulum sapien, imperdiet sodales tellus malesuada quis. Curabitur imperdiet enim pharetra lectus molestie, ut imperdiet purus pretium. Aliquam consectetur malesuada tortor, a lacinia arcu laoreet ut. Nulla vestibulum tortor nunc, maximus tempus dolor iaculis sit amet. Maecenas cursus quis mauris sed lobortis. Nam vehicula mauris nec ante tincidunt, vel malesuada tellus imperdiet. Praesent cursus tellus ligula, eu egestas nunc gravida in. Nunc consequat porta urna et posuere. Pellentesque lacinia tincidunt arcu at auctor. Nunc vehicula sem vel commodo imperdiet. Proin fringilla ac lorem suscipit sagittis. Nulla congue interdum purus, id tempus libero vulputate id. Vivamus feugiat dolor mauris, sed consectetur dui ornare lobortis.\n",
            "\n",
            "Quisque nibh est, suscipit luctus tortor tincidunt, iaculis tincidunt tortor. Suspendisse mattis dui elementum suscipit laoreet. Ut sollicitudin elit nec eros tempus venenatis. Mauris ex libero, sollicitudin pretium orci placerat, semper mattis metus. Proin tincidunt dapibus diam, sit amet vehicula nisi porta id. Sed et turpis mauris. Etiam vitae vulputate risus. Donec consequat venenatis neque vitae euismod. Vivamus eleifend hendrerit lectus a fermentum. Curabitur eget lectus ut dui eleifend efficitur ac vitae ligula. Vestibulum auctor,\n",
            "Score: 0.1739269409080692\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=query_engine.query(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tm4AUt9Zm7Al",
        "outputId": "8982fb60-234b-421d-a850-231cb5d4a54d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "MbgyPPg-fDAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ccb0d70e-c024-49e9-f6b3-e6cca33c0838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Response: This document appears to be a sample text or a\n",
            "template for a document, likely a business or marketing document,\n",
            "given the use of Latin phrases such as \"Lorem ipsum dolor sit amet\"\n",
            "and the structure of the text. The content is a collection of\n",
            "paragraphs with varying lengths, each containing a mix of Latin\n",
            "phrases, words, and phrases in English. The text does not appear to be\n",
            "a coherent narrative or a formal report, but rather a collection of\n",
            "phrases and sentences used to fill space or create a visually\n",
            "appealing layout. Without more context, it is difficult to determine\n",
            "the specific purpose or content of the document.\n",
            "______________________________________________________________________\n",
            "Source Node 1/2\n",
            "Node ID: 64b3c297-992b-4418-a086-87f38898222e\n",
            "Similarity: 0.18062013069197172\n",
            "Text: ante odio, ut interdum tellus imperdiet vitae. Lorem ipsum dolor\n",
            "sit amet, consectetur adipiscing elit. Suspendisse commodo, tellus ac\n",
            "varius egestas, magna nisi condimentum nunc, vitae tincidunt nisl\n",
            "lorem eget eros. Duis tristique ultrices magna, a varius ligula ornare\n",
            "pharetra. Fusce luctus nisl est, ac semper nunc dignissim tempor.\n",
            "Praesent...\n",
            "______________________________________________________________________\n",
            "Source Node 2/2\n",
            "Node ID: 1da33f7d-abd4-4d6d-8821-440580f0a2ac\n",
            "Similarity: 0.1739269409080692\n",
            "Text: consequat quis quam ut facilisis. Nam non magna cursus massa\n",
            "semper mattis. Vivamus rhoncus, augue vitae efficitur posuere, mauris\n",
            "justo laoreet neque, in iaculis tellus erat ut ipsum. Suspendisse odio\n",
            "augue, tincidunt id lectus sed, hendrerit efficitur sem. Duis vitae\n",
            "nibh pulvinar, tincidunt orci a, mollis ex. Integer condimentum justo\n",
            "enim, e...\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.response.pprint_utils import pprint_response\n",
        "pprint_response(response,show_source=True)\n",
        "#print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Rerank\n",
        "[Query Bundle](https://docs.llamaindex.ai/en/v0.10.17/api/llama_index.core.schema.QueryBundle.html#querybundle)"
      ],
      "metadata": {
        "id": "wBKsMgp132C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from llama_index.core.retrievers import VectorIndexRetriever (Already Imported)\n",
        "from llama_index.core import QueryBundle\n",
        "from llama_index.core.indices.postprocessor import LLMRerank\n",
        "\n",
        "#from typing import List\n",
        "\n",
        "retriever2 = VectorIndexRetriever(\n",
        "        index=index,\n",
        "        similarity_top_k=5,\n",
        "        #vector_store_query_mode=\"default\",\n",
        "\n",
        "    )\n",
        "\n",
        "query_bundle = QueryBundle(prompt)\n",
        "\n",
        "retrieved_nodes = retriever2.retrieve(query_bundle)\n",
        "\n",
        "reranker = LLMRerank(\n",
        "            choice_batch_size=5,\n",
        "            top_n=5,\n",
        "        )\n",
        "retrieved_nodes = reranker.postprocess_nodes(\n",
        "            retrieved_nodes, query_bundle\n",
        "        )\n",
        "query_engine2=RetrieverQueryEngine(retriever=retriever2)\n",
        "#pprint_response(retrieved_nodes,show_source=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyPPctlZUxz0",
        "outputId": "52c444fd-0eec-4a34-840e-63faa21f93d0"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Retrieved {len(retrieved_nodes)} nodes:\")\n",
        "for i, node in enumerate(retrieved_nodes):\n",
        "    print(f\"\\n--- Node {i + 1} ---\")\n",
        "    print(node.get_content())\n",
        "    print(f\"Score: {node.score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QxUlnnoXkk9f",
        "outputId": "163ee688-6fd8-40f7-e37b-33347c6f6813"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved 2 nodes:\n",
            "\n",
            "--- Node 1 ---\n",
            "ante odio, ut interdum tellus imperdiet vitae. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse commodo, tellus ac varius egestas, magna nisi condimentum nunc, vitae tincidunt nisl lorem eget eros. Duis tristique ultrices magna, a varius ligula ornare pharetra. Fusce luctus nisl est, ac semper nunc dignissim tempor.\n",
            "\n",
            "Praesent sed lorem lorem. Donec egestas eros nec rhoncus efficitur. Duis nec mi arcu. Suspendisse in elit elit. Suspendisse potenti. Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Quisque mattis metus eu nisi commodo, in semper orci malesuada. Nullam ullamcorper dapibus dolor in egestas.\n",
            "\n",
            "Aenean faucibus dui sit amet interdum laoreet. Sed ac pretium arcu, at dictum nisl. Donec ullamcorper ac diam et finibus. Suspendisse hendrerit lorem sem, ut mattis ipsum malesuada vel. Morbi ullamcorper elementum viverra. Fusce eget placerat urna, et ornare tortor. Suspendisse facilisis lorem at nunc semper rhoncus. Quisque volutpat non est vitae dapibus. Suspendisse imperdiet facilisis nibh nec sodales.\n",
            "\n",
            "Cras sagittis porttitor odio, in pretium mauris finibus ut. Aliquam venenatis magna massa, id accumsan mi blandit quis. In vehicula euismod mollis. Donec volutpat, tortor in auctor cursus, urna nibh scelerisque magna, nec consectetur odio magna nec nisi. Suspendisse commodo euismod diam eget rutrum. Suspendisse vel laoreet ex. In sed sodales nisl. Sed et hendrerit magna. Suspendisse pulvinar id elit sit amet scelerisque. Suspendisse dictum nisl in sapien iaculis ultrices in a risus. In tristique sapien est, vel mollis magna egestas at. Aenean ullamcorper nisl at metus feugiat, non egestas urna bibendum.\n",
            "\n",
            "Quisque pharetra ac nunc at tincidunt. Nulla vel ipsum nec elit blandit hendrerit. Quisque magna eros, imperdiet non elementum id, blandit nec eros. Etiam pharetra condimentum mi, sit amet dictum dolor vulputate ut. Nam pellentesque velit a ullamcorper condimentum. Integer orci dui, elementum non augue non, accumsan facilisis augue. Phasellus pharetra lorem et eros vehicula varius. Vestibulum elementum nunc eget sagittis laoreet. Suspendisse mauris massa, aliquet sed eros ac, tempus elementum nisl. Integer vel congue libero, at sagittis dui. Aliquam viverra nisl dolor, ac volutpat neque maximus vel. Etiam faucibus fermentum nulla malesuada rutrum. Pellentesque imperdiet tincidunt augue.\n",
            "\n",
            "Phasellus sagittis quis justo gravida placerat. Praesent congue mattis nulla, vitae vehicula tortor efficitur in. Maecenas cursus odio risus, dictum molestie enim pulvinar ut. Praesent nibh erat, accumsan a tellus vel, fringilla ultrices sem. Donec vel enim a orci mollis scelerisque. Mauris at imperdiet metus. Nulla commodo fermentum ex a varius. Morbi ac quam non nisl pellentesque feugiat. Praesent a aliquet elit, vitae imperdiet felis. Donec bibendum ipsum metus, quis rhoncus orci convallis at. Duis pharetra nisl id blandit malesuada. Donec sodales a eros fringilla congue.\n",
            "\n",
            "Etiam eleifend massa non sapien viverra fringilla. Vivamus tempor sodales ante eu finibus. Phasellus sit amet elementum diam. Phasellus eget diam diam. Nunc rutrum lacus ut elementum congue. Donec justo felis, tempus ac sodales vitae, faucibus sit amet nibh. Nam consequat sit amet nisi a hendrerit. Ut auctor non lectus eu semper. Curabitur sollicitudin libero vitae ante pulvinar, vel laoreet nunc finibus. Praesent vel convallis\n",
            "Score: 10.0\n",
            "\n",
            "--- Node 2 ---\n",
            "consequat quis quam ut facilisis. Nam non magna cursus massa semper mattis. Vivamus rhoncus, augue vitae efficitur posuere, mauris justo laoreet neque, in iaculis tellus erat ut ipsum. Suspendisse odio augue, tincidunt id lectus sed, hendrerit efficitur sem. Duis vitae nibh pulvinar, tincidunt orci a, mollis ex. Integer condimentum justo enim, eget ultricies libero bibendum sed. Duis magna mi, mattis sit \n",
            "\n",
            "\n",
            "\n",
            "amet diam quis, efficitur vehicula est. Etiam tincidunt turpis urna, ut dignissim risus lacinia in. Suspendisse a mollis magna, eu feugiat massa. Ut vitae erat vel tellus condimentum placerat venenatis a erat.\n",
            "\n",
            "Suspendisse molestie nibh magna, eu maximus ante tincidunt tincidunt. Ut sit amet bibendum turpis, vitae iaculis nibh. Pellentesque consectetur facilisis sem, sed vehicula quam consectetur dapibus. Praesent eget urna aliquet, sollicitudin massa ut, tempor quam. In vehicula feugiat dui sed feugiat. Nulla laoreet placerat dui, congue placerat massa lobortis in. Curabitur eu pellentesque enim, vel congue dolor. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed placerat vulputate risus a convallis. Suspendisse laoreet volutpat libero id vulputate. Quisque sit amet scelerisque elit, vel ultrices felis. Vivamus tristique ex vitae maximus commodo.\n",
            "\n",
            "Donec vestibulum tellus nec pellentesque imperdiet. Praesent fringilla molestie felis ut porta. Cras ac finibus ante. In ultricies nec sapien ac cursus. Duis semper scelerisque mi, non posuere urna scelerisque non. Pellentesque orci dui, scelerisque nec bibendum at, pellentesque vel nulla. Curabitur nec tempus ante. Praesent tortor arcu, egestas eu tellus nec, aliquam porta velit. Nam et urna id sem aliquam gravida. Suspendisse lacus ligula, facilisis ut sapien non, eleifend sodales risus. In a lacus eu nisi accumsan vulputate sed fringilla quam. Vivamus eros erat, suscipit vel rhoncus eu, venenatis sed mauris. Ut mollis imperdiet elit, vel vulputate massa ultricies non. Duis fermentum lectus ac lorem venenatis tempor.\n",
            "\n",
            "Integer in vestibulum magna, a ornare dolor. Donec consectetur vestibulum sapien, imperdiet sodales tellus malesuada quis. Curabitur imperdiet enim pharetra lectus molestie, ut imperdiet purus pretium. Aliquam consectetur malesuada tortor, a lacinia arcu laoreet ut. Nulla vestibulum tortor nunc, maximus tempus dolor iaculis sit amet. Maecenas cursus quis mauris sed lobortis. Nam vehicula mauris nec ante tincidunt, vel malesuada tellus imperdiet. Praesent cursus tellus ligula, eu egestas nunc gravida in. Nunc consequat porta urna et posuere. Pellentesque lacinia tincidunt arcu at auctor. Nunc vehicula sem vel commodo imperdiet. Proin fringilla ac lorem suscipit sagittis. Nulla congue interdum purus, id tempus libero vulputate id. Vivamus feugiat dolor mauris, sed consectetur dui ornare lobortis.\n",
            "\n",
            "Quisque nibh est, suscipit luctus tortor tincidunt, iaculis tincidunt tortor. Suspendisse mattis dui elementum suscipit laoreet. Ut sollicitudin elit nec eros tempus venenatis. Mauris ex libero, sollicitudin pretium orci placerat, semper mattis metus. Proin tincidunt dapibus diam, sit amet vehicula nisi porta id. Sed et turpis mauris. Etiam vitae vulputate risus. Donec consequat venenatis neque vitae euismod. Vivamus eleifend hendrerit lectus a fermentum. Curabitur eget lectus ut dui eleifend efficitur ac vitae ligula. Vestibulum auctor,\n",
            "Score: 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response2=query_engine2.query(query_bundle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bqLwOHxhnMQm",
        "outputId": "b1f57af9-24ae-428a-e74b-0394f8804f21"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.response.pprint_utils import pprint_response\n",
        "pprint_response(response2,show_source=True)\n",
        "#print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "67cWu9A5nZJN",
        "outputId": "07df7ce7-17e0-4b08-e72a-82146154e9e7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Response: This document appears to be a sample text or a\n",
            "placeholder content, likely used for demonstration or testing\n",
            "purposes. It does not contain any specific information or content that\n",
            "can be summarized or analyzed. The text is composed of a series of\n",
            "paragraphs with varying lengths, and it seems to be a collection of\n",
            "random sentences and phrases. Without more context or information, it\n",
            "is difficult to determine the purpose or meaning of this document. The\n",
            "document's content is not related to any specific topic or subject,\n",
            "and it does not provide any clear or concise information. The text is\n",
            "likely a generic placeholder or a sample text used for testing or\n",
            "demonstration purposes.   Note: The refined answer is based on the\n",
            "provided context, which is a large block of text that appears to be a\n",
            "sample document. The context does not provide any specific information\n",
            "about the document's purpose or content, so the refined answer is\n",
            "similar to the original answer. If more context were provided, the\n",
            "refined answer could be more accurate.\n",
            "______________________________________________________________________\n",
            "Source Node 1/5\n",
            "Node ID: 64b3c297-992b-4418-a086-87f38898222e\n",
            "Similarity: 0.18062013069197172\n",
            "Text: ante odio, ut interdum tellus imperdiet vitae. Lorem ipsum dolor\n",
            "sit amet, consectetur adipiscing elit. Suspendisse commodo, tellus ac\n",
            "varius egestas, magna nisi condimentum nunc, vitae tincidunt nisl\n",
            "lorem eget eros. Duis tristique ultrices magna, a varius ligula ornare\n",
            "pharetra. Fusce luctus nisl est, ac semper nunc dignissim tempor.\n",
            "Praesent...\n",
            "______________________________________________________________________\n",
            "Source Node 2/5\n",
            "Node ID: 1da33f7d-abd4-4d6d-8821-440580f0a2ac\n",
            "Similarity: 0.1739269409080692\n",
            "Text: consequat quis quam ut facilisis. Nam non magna cursus massa\n",
            "semper mattis. Vivamus rhoncus, augue vitae efficitur posuere, mauris\n",
            "justo laoreet neque, in iaculis tellus erat ut ipsum. Suspendisse odio\n",
            "augue, tincidunt id lectus sed, hendrerit efficitur sem. Duis vitae\n",
            "nibh pulvinar, tincidunt orci a, mollis ex. Integer condimentum justo\n",
            "enim, e...\n",
            "______________________________________________________________________\n",
            "Source Node 3/5\n",
            "Node ID: 2f6eba08-5b51-4358-acec-a45dd657be05\n",
            "Similarity: 0.16039359320320754\n",
            "Text: in imperdiet consequat. Praesent ullamcorper erat tortor, at\n",
            "aliquam nulla fringilla vitae. Cras sodales, odio ac dapibus\n",
            "consectetur, ipsum mi ultrices neque, vel vestibulum purus eros\n",
            "aliquet risus. Vestibulum ac sagittis dui. Integer quis lectus\n",
            "egestas, sodales nunc eget, dignissim turpis. Nulla sodales\n",
            "ullamcorper imperdiet. Etiam dolor aug...\n",
            "______________________________________________________________________\n",
            "Source Node 4/5\n",
            "Node ID: 14b096b8-5289-441c-856e-77b7a4734944\n",
            "Similarity: 0.1425019377502522\n",
            "Text: convallis sapien ac scelerisque mollis. Donec semper massa eu\n",
            "lacinia dapibus. Nulla facilisi. Duis et eros vitae tellus congue\n",
            "aliquet. Aliquam ac augue molestie, dapibus enim ut, tincidunt velit.\n",
            "Etiam sollicitudin purus sed purus ultricies, ultrices eleifend purus\n",
            "vulputate. In quis ex sit amet magna cursus posuere id sit amet purus.\n",
            "Integer...\n",
            "______________________________________________________________________\n",
            "Source Node 5/5\n",
            "Node ID: aed33d74-fbc5-438b-8bb3-dfbec27f0742\n",
            "Similarity: 0.14245259540803162\n",
            "Text: Curabitur bibendum ante urna, sed blandit libero egestas id.\n",
            "Pellentesque rhoncus elit in lacus ultrices fringilla. Nam ac metus eu\n",
            "turpis mattis rutrum. Mauris mattis sem ex, facilisis molestie sapien\n",
            "luctus non. Vestibulum tincidunt urna at odio suscipit, vel congue\n",
            "felis cursus. Etiam tellus magna, egestas ac suscipit in, laoreet quis\n",
            "felis. ...\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "wBKsMgp132C4"
      ],
      "gpuType": "T4",
      "mount_file_id": "1bV96jIFhaGZ-yb18c6xo-54ljlfaA0CO",
      "authorship_tag": "ABX9TyMZaf+AdQruU21hClqLrebP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}